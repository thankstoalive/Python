{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train/train.csv')\n",
    "test = pd.read_csv('./test/test.csv')\n",
    "\n",
    "train.drop(['Name', 'Description', 'PetID'], axis=1, inplace=True)\n",
    "test.drop(['Name', 'Description', 'PetID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10495, 21), (4498, 21))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make train, val data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(train, test_size=0.3, random_state=0)\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = df_train['AdoptionSpeed']\n",
    "train_X = df_train.drop(['AdoptionSpeed'], axis=1)\n",
    "\n",
    "test_y = df_test['AdoptionSpeed']\n",
    "test_X = df_test.drop(['AdoptionSpeed'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10495, 20)\n",
      "(4498, 20)\n"
     ]
    }
   ],
   "source": [
    "# categorical variable\n",
    "numeric_cols = ['Age', 'Quantity', 'Fee', 'VideoAmt', 'PhotoAmt']\n",
    "cat_cols = list(set(train_X.columns) - set(numeric_cols))\n",
    "for i in cat_cols:\n",
    "    train_X.loc[:, i] = train_X[i].astype('category')\n",
    "    test_X.loc[:, i] = test_X[i].astype('category')\n",
    "print(train_X.shape)\n",
    "print(test_X.shape)\n",
    "\n",
    "# get categorical variable index\n",
    "\n",
    "foo = train_X.dtypes\n",
    "cat_feature_names = foo[foo == \"category\"]\n",
    "cat_features = [train_X.columns.get_loc(c) for c in train_X.columns if c in cat_feature_names]\n",
    "\n",
    "# y 타입 지정\n",
    "train_y = train_y.astype('category')\n",
    "test_y = test_y.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load a numpy array into Dataset\n",
    "\n",
    "d_train = lgb.Dataset(train_X, label=train_y)\n",
    "d_valid = lgb.Dataset(test_X, label=test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM 파라미터 for classification\n",
    "params_c = {'application': 'multiclass',\n",
    "          'num_class':5,\n",
    "          'metric': 'multi_logloss',\n",
    "            }\n",
    "\n",
    "# LightGBM 파라미터 for regression\n",
    "params_r = {'application': 'regression',\n",
    "           'metric': 'rmse',\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's multi_logloss: 1.44205\tvalid_1's multi_logloss: 1.44707\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[2]\ttraining's multi_logloss: 1.42033\tvalid_1's multi_logloss: 1.43204\n",
      "[3]\ttraining's multi_logloss: 1.40071\tvalid_1's multi_logloss: 1.41882\n",
      "[4]\ttraining's multi_logloss: 1.38357\tvalid_1's multi_logloss: 1.40799\n",
      "[5]\ttraining's multi_logloss: 1.36761\tvalid_1's multi_logloss: 1.39787\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5]\ttraining's multi_logloss: 1.36761\tvalid_1's multi_logloss: 1.39787\n"
     ]
    }
   ],
   "source": [
    "model = lgb.train(params_c,\n",
    "                      train_set = d_train,\n",
    "                      valid_sets = [d_train, d_valid],\n",
    "                      num_boost_round = 5,\n",
    "                      verbose_eval = 1,\n",
    "                      categorical_feature = cat_features,\n",
    "                      early_stopping_rounds = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02779198, 0.19949399, 0.25291441, 0.21834876, 0.30145086],\n",
       "       [0.02470831, 0.20102968, 0.2547208 , 0.20481533, 0.31472587],\n",
       "       [0.03096301, 0.23691988, 0.27373753, 0.20767597, 0.2507036 ],\n",
       "       ...,\n",
       "       [0.03346714, 0.21767494, 0.2443351 , 0.21851824, 0.28600459],\n",
       "       [0.03176305, 0.23556865, 0.27336912, 0.205858  , 0.25344119],\n",
       "       [0.02464185, 0.20210166, 0.26672457, 0.20217954, 0.30435238]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_y = model.predict(test_X, num_iteration=model.best_iteration)\n",
    "pred_test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 2, ..., 4, 2, 4], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(pred_test_y, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's rmse: 1.15927\tvalid_1's rmse: 1.15637\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[2]\ttraining's rmse: 1.14247\tvalid_1's rmse: 1.14263\n",
      "[3]\ttraining's rmse: 1.1282\tvalid_1's rmse: 1.13159\n",
      "[4]\ttraining's rmse: 1.11573\tvalid_1's rmse: 1.12198\n",
      "[5]\ttraining's rmse: 1.10404\tvalid_1's rmse: 1.11376\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5]\ttraining's rmse: 1.10404\tvalid_1's rmse: 1.11376\n"
     ]
    }
   ],
   "source": [
    "model = lgb.train(params_r,\n",
    "                      train_set = d_train,\n",
    "                      valid_sets = [d_train, d_valid],\n",
    "                      num_boost_round = 5, # number of boosting iterations\n",
    "                      verbose_eval = 1, # n번마다 print \n",
    "                      categorical_feature = cat_features,\n",
    "                      early_stopping_rounds = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.59686384, 2.61883125, 2.28940823, ..., 2.40792863, 2.34586271,\n",
       "       2.46956264])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_y = model.predict(test_X, num_iteration=model.best_iteration)\n",
    "pred_test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
